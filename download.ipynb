{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on 2019.5.1\n",
    "\n",
    "@author: wujin\n",
    "'''\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def maybe_download_from_url(url, download_dir):\n",
    "    \"\"\"\n",
    "    Download the data from url, unless it's already here.\n",
    "    Args:\n",
    "        download_dir: string, path to download directory\n",
    "        url: url to download from\n",
    "    Returns:\n",
    "        Path to the downloaded file\n",
    "    \"\"\"\n",
    "    filename = url.split('/')[-1]\n",
    "    filepath = os.path.join(download_dir, filename)\n",
    "\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        print('Downloading: \"{}\"'.format(filepath))\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Download complete ({} bytes)'.format(size))\n",
    "    else:\n",
    "        print('File already exists: \"{}\"'.format(filepath))\n",
    "\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def maybe_download_from_google_drive(id, filepath):\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, filepath, chunk_size=32 * 1024):\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size), total=total_size,\n",
    "                              unit='B', unit_scale=True, desc=filepath):\n",
    "                if chunk:  # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        print('Downloading: \"{}\"'.format(filepath))\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "        session = requests.Session()\n",
    "\n",
    "        response = session.get(URL, params={'id': id}, stream=True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = {'id': id, 'confirm': token}\n",
    "            response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "        save_response_content(response, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Download complete ({} bytes)'.format(size))\n",
    "    else:\n",
    "        print('File already exists: \"{}\"'.format(filepath))\n",
    "\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def maybe_extract(compressed_filepath, train_dir, test_dir):\n",
    "    def is_image(filepath):\n",
    "        extensions = ('.jpg', '.jpeg', '.png', '.gif')\n",
    "        return any(filepath.endswith(ext) for ext in extensions)\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    print('Extracting: \"{}\"'.format(compressed_filepath))\n",
    "\n",
    "    if zipfile.is_zipfile(compressed_filepath):\n",
    "        with zipfile.ZipFile(compressed_filepath) as zf:\n",
    "            files = [member for member in zf.infolist() if is_image(member.filename)]\n",
    "            count = len(files)\n",
    "            train_test_boundary = int(count * 0.99)\n",
    "            for i in range(count):\n",
    "                if i < train_test_boundary:\n",
    "                    extract_dir = train_dir\n",
    "                else:\n",
    "                    extract_dir = test_dir\n",
    "\n",
    "                if not os.path.exists(os.path.join(extract_dir, files[i].filename)):\n",
    "                    zf.extract(files[i], extract_dir)\n",
    "    elif tarfile.is_tarfile(compressed_filepath):\n",
    "        with tarfile.open(compressed_filepath) as tar:\n",
    "            files = [member for member in tar if is_image(member.name)]\n",
    "            count = len(files)\n",
    "            train_test_boundary = int(count * 0.99)\n",
    "            for i in range(count):\n",
    "                if i < train_test_boundary:\n",
    "                    extract_dir = train_dir\n",
    "                else:\n",
    "                    extract_dir = test_dir\n",
    "\n",
    "                if not os.path.exists(os.path.join(extract_dir, files[i].name)):\n",
    "                    tar.extract(files[i], extract_dir)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "\n",
    "    print('Extraction complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
